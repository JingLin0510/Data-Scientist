{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a KMeans instance with 3 clusters: model\n",
    "model = KMeans(3)\n",
    "# Fit model to points\n",
    "model.fit(points)\n",
    "# Determine the cluster labels of new_points: labels\n",
    "labels = model.predict(new_points)\n",
    "# Print cluster labels of new_points\n",
    "print(labels)\n",
    "# Assign the columns of new_points: xs and ys\n",
    "xs = new_points[:,0]\n",
    "ys = new_points[:,1]\n",
    "# Make a scatter plot of xs and ys, using labels to define the colors\n",
    "plt.scatter(xs, ys, c=labels, alpha=0.5)\n",
    "# Assign the cluster centers: centroids\n",
    "centroids = model.cluster_centers_\n",
    "# Assign the columns of centroids: centroids_x, centroids_y\n",
    "centroids_x = centroids[:,0]\n",
    "centroids_y = centroids[:,1]\n",
    "# Make a scatter plot of centroids_x and centroids_y\n",
    "plt.scatter(centroids_x, centroids_y, marker='D', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 6)\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    # Create a KMeans instance with k clusters: model\n",
    "    model = KMeans(n_clusters=k)\n",
    "    # Fit model to samples\n",
    "    model.fit(samples)\n",
    "    # Append the inertia to the list of inertias\n",
    "    inertias.append(model.inertia_)\n",
    "# Plot ks vs inertias\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KMeans model with 3 clusters: model\n",
    "model = KMeans(3)\n",
    "# Use fit_predict to fit model and obtain cluster labels: labels\n",
    "labels = model.fit_predict(samples)\n",
    "# Create a DataFrame with labels and varieties as columns: df\n",
    "df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n",
    "# Create crosstab: ct\n",
    "ct = pd.crosstab(df.labels, df.varieties)\n",
    "# Display ct\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variance of a feature measures spread of its values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization with hierarchical clustering and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(samples, method='complete')\n",
    "# Plot the dendrogram, using varieties as labels\n",
    "dendrogram(mergings,\n",
    "           labels=varieties,\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=6,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "height on dendrogram = distance between merging clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE for 2d maps <br>\n",
    "1. t-SNE: t-distributed stochastic neighbor embedding <br>\n",
    "2. maps samples to 2D space (or 3D) <br>\n",
    "3. map approximately preserves nearness of samples <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "# Create a TSNE instance: model\n",
    "model = TSNE(learning_rate=50)\n",
    "# Apply fit_transform to samples: tsne_features\n",
    "tsne_features = model.fit_transform(normalized_movements)\n",
    "# Select the 0th feature: xs\n",
    "xs = tsne_features[:,0]\n",
    "# Select the 1th feature: ys\n",
    "ys = tsne_features[:,1]\n",
    "# Scatter plot\n",
    "_ = plt.scatter(xs, ys, alpha=0.5)\n",
    "# Annotate the points\n",
    "for x, y, company in zip(xs, ys, companies):\n",
    "    plt.annotate(company, (x, y), fontsize=5, alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorrelating your data and dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA: principle component analysis <br>\n",
    "principle component = directions of variance <br>\n",
    "intrinsic dimension: number of features needed to approximate the dastaset <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import pearsonr\n",
    "# Create PCA instance: model\n",
    "model = PCA()\n",
    "# Apply the fit_transform method of model to grains: pca_features\n",
    "pca_features = model.fit_transform(grains)\n",
    "# Assign 0th column of pca_features: xs\n",
    "xs = pca_features[:,0]\n",
    "# Assign 1st column of pca_features: ys\n",
    "ys = pca_features[:,1]\n",
    "# Scatter plot xs vs ys\n",
    "plt.scatter(xs, ys)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "# Calculate the Pearson correlation of xs and ys\n",
    "correlation, pvalue = pearsonr(xs, ys)\n",
    "# Display the correlation\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot of the untransformed points\n",
    "plt.scatter(grains[:,0], grains[:,1])\n",
    "# Create a PCA instance: model\n",
    "model = PCA()\n",
    "# Fit model to points\n",
    "model.fit(grains)\n",
    "# Get the mean of the grain samples: mean\n",
    "mean = model.mean_\n",
    "# Get the first principal component: first_pc\n",
    "first_pc = model.components_[0,:]\n",
    "# Plot first_pc as an arrow, starting at mean\n",
    "plt.arrow(mean[0], mean[1], first_pc[0], first_pc[1], color='red', width=0.01)\n",
    "# Keep axes on same scale\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse 稀疏的 array: most entries are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# Create a PCA model with 2 components: pca\n",
    "pca = PCA(n_components=2)\n",
    "# Fit the PCA instance to the scaled samples\n",
    "pca.fit(scaled_samples)\n",
    "# Transform the scaled samples: pca_features\n",
    "pca_features = pca.transform(scaled_samples)\n",
    "# Print the shape of pca_features\n",
    "print(pca_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create a TfidfVectorizer: tfidf\n",
    "tfidf = TfidfVectorizer()\n",
    "# Apply fit_transform to document: csr_mat\n",
    "csr_mat = tfidf.fit_transform(documents)\n",
    "# Print result of toarray() method\n",
    "print(csr_mat.toarray())\n",
    "# Get the words: words\n",
    "words = tfidf.get_feature_names()\n",
    "# Print words\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering interpretable features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF: non-negative matrix factorization <br>\n",
    "1. dimension reduction technique <br>\n",
    "2. NMF models are interpretable (unlike PCA) <br>\n",
    "3. all sample feature must be non-negative <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf-idf: term frequency-inverse document frequency is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus 语料库."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NMF\n",
    "from sklearn.decomposition import NMF\n",
    "# Create an NMF instance: model\n",
    "model = NMF(n_components=6)\n",
    "# Fit the model to articles\n",
    "model.fit(articles)\n",
    "# Transform the articles: nmf_features\n",
    "nmf_features = model.transform(articles)\n",
    "# Print the NMF features\n",
    "print(nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "# Select the 0th row: digit\n",
    "digit = samples[0,:]\n",
    "# Print digit\n",
    "print(digit)\n",
    "# Reshape digit to a 13x8 array: bitmap\n",
    "bitmap = digit.reshape(13,8)\n",
    "# Print bitmap\n",
    "print(bitmap)\n",
    "# Use plt.imshow to display bitmap\n",
    "plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the necessary imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "# Normalize the NMF features: norm_features\n",
    "norm_features = normalize(nmf_features)\n",
    "# Create a DataFrame: df\n",
    "df = pd.DataFrame(norm_features, index=titles)\n",
    "# Select the row corresponding to 'Cristiano Ronaldo': article\n",
    "article = df.loc['Cristiano Ronaldo']\n",
    "# Compute the dot products: similarities\n",
    "similarities = df.dot(article)\n",
    "# Display those with the largest cosine similarity\n",
    "print(similarities.nlargest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
